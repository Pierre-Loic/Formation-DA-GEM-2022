{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e394d112",
   "metadata": {},
   "source": [
    "# üë©‚Äçüíª Activit√© 2 : Comment r√©cup√©rer des donn√©es ? - PARTIE 2 : API, bases de donn√©es et web scraping\n",
    "\n",
    "<img src=\"https://cdn.pixabay.com/photo/2022/05/23/17/28/big-data-7216774_960_720.png\" alt=\"base de donn√©es\" width=\"400\"/>\n",
    "\n",
    "#### [Pierre-Loic BAYART](https://www.linkedin.com/in/pierreloicbayart/) - Formation d√©veloppeur d'applications sp√©cialisation data analyst - Webforce3 - Grenoble Ecole de Management\n",
    "\n",
    "### Code pour indiquer l'importance des notions trait√©es dans cette activit√©\n",
    "\n",
    "- #### ü•á : connaissance fondamentale pour l'analyse de donn√©es\n",
    "- #### ü•à : connaissance importante pour l'analyse de donn√©es\n",
    "- #### ü•â : connaissance moins importante pour l'analyse de donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d9f0c",
   "metadata": {},
   "source": [
    "## üîç Recherche d'informations\n",
    "\n",
    "En recherchant sur le web, trouver les r√©ponses aux questions suivantes :\n",
    "\n",
    "### - A quoi sert une API ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - Quelles sont les deux grandes cat√©gories de bases de donn√©es ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - Quelle diff√©rence fondamentale existe-t-il entre une base de donn√©es SQLite et PostgreSQL ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - Quelles sont les biblioth√®ques Python utiles pour travailler avec des bases de donn√©es ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - En quoi consiste le web scraping ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - Quelles sont les biblioth√®ques Python utiles pour faire du web scraping ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___\n",
    "### - Pourquoi les algorithmes de web scraping demandent-ils en g√©n√©ral beaucoup de maintenance ?\n",
    "___\n",
    "*A COMPLETER*\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb65b268",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Activit√©s\n",
    "\n",
    "### ü•á API (Application Programming Interface)\n",
    "\n",
    "Les API permettent de **r√©cup√©rer facilement des donn√©es** depuis un serveur de mani√®re **normalis√©e** et ind√©pendamment du langage de programmation utilis√©. Pour r√©cup√©rer les donn√©es d'une **API** en **Python**, il faut utiliser une biblioth√®que qui permet d'**appeler un serveur** comme par exemple **[urllib](https://docs.python.org/fr/3/library/urllib.html) (biblioth√®que standard)** ou **[requests](https://requests.readthedocs.io/en/latest/) (biblioth√®que externe)**\n",
    "\n",
    "- Effectuer une recherche du mot \"Github\" avec l'**API Opensearch de Wikipedia** en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16473f64",
   "metadata": {},
   "source": [
    "### ü•á Bases de donn√©es\n",
    "\n",
    "Les bases de donn√©es relationnelles **SQLite** ont l'avantage de **ne pas n√©cessiter de serveur** de base de donn√©es. Dans cette partie, on va cr√©er une base de donn√©es SQLite √† partir d'un **fichier CSV**.\n",
    "\n",
    "- Gr√¢ce √† la biblioth√®que **sqlalchemy**, cr√©er un **moteur de base de donn√©es SQLite** avec la m√©thode [`sqlalchemy.create_engine()`](https://docs.sqlalchemy.org/en/20/core/engines.html#sqlite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88727bfe",
   "metadata": {},
   "source": [
    "- R√©cup√©rer dans un **dataframe Pandas** les donn√©es de la [Base officielle des codes postaux](https://www.data.gouv.fr/fr/datasets/base-officielle-des-codes-postaux/) √† partir du **fichier CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bebd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff1904",
   "metadata": {},
   "source": [
    "- Cre√©r une **table \"CodePostaux\"** dans la base de donn√©es gr√¢ce √† la m√©thode [`pandas.DataFrame.to_sql()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e95452",
   "metadata": {},
   "source": [
    "- Ex√©cuter une **requ√™te SQL** sur la base de donn√©es pour v√©rifier que les donn√©es ont **bien √©t√© ins√©r√©es**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd5822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04a296",
   "metadata": {},
   "source": [
    "### ü•à Web scraping\n",
    "\n",
    "Dans un premier temps, on va utiliser les fonctions suivantes de **Pandas** qui permettent de **r√©cup√©rer des donn√©es sur le web** : [`pandas.read_html()`](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) et [`pandas.read_clipboard()`](https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html). Ceci fonctionne bien si les **tableaux HTML sont bien construits**. Dans le cas contraire, il faut effectuer un **scraping plus \"manuel\"** (avec les biblioth√®ques [Beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), [Scrapy](https://scrapy.org/) ou [Selenium](https://selenium-python.readthedocs.io/) par exemple).\n",
    "\n",
    "- Gr√¢ce √† la fonction [`pandas.read_html()`](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) de Pandas, r√©cup√©rer le tableau de la distribution des salaires mensuels nets en France - [Figure 2](https://www.insee.fr/fr/statistiques/6436313#tableau-figure2). Utiliser le param√®tres `attrs` de la m√©thode `read_html()` pour ne r√©cup√©rer que le tableau voulu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951e8c9",
   "metadata": {},
   "source": [
    "- Tranformer la colonne \"Effectifs (en¬†EQTP)\" en **integer** (attention au caract√®re \"\\xa0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ce816",
   "metadata": {},
   "source": [
    "- Gr√¢ce √† la biblioth√®que Matplotlib ou Seaborn, tracer l'**histogramme des donn√©es**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9133aee",
   "metadata": {},
   "source": [
    "- ü•á Gr√¢ce √† la m√©thode de dataframe [`pandas.DataFrame.to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html), cr√©er un **fichier CSV** √† partir des donn√©es r√©cup√©r√©es sur le web qui sera r√©utilis√© dans l'activit√© N¬∞3. V√©rifier son contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aae157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14158054",
   "metadata": {},
   "source": [
    "- ü•âGr√¢ce √† la fonction [`pandas.read_clipboard()`](https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html), r√©cup√©rer le tableau de la r√©partition des salaires - [Figure 3](https://www.insee.fr/fr/statistiques/6436313#tableau-figure3) dans un dataframe **depuis le presse-papier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc74957",
   "metadata": {},
   "source": [
    "- ü•á Gr√¢ce √† la m√©thode de dataframe [`pandas.DataFrame.to_json()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html), cr√©er un **fichier JSON** √† partir des donn√©es r√©cup√©r√©es sur le web qui sera r√©utilis√© dans l'activit√© N¬∞3. V√©rifier son contenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049df989",
   "metadata": {},
   "source": [
    "Dans cette partie, on va effectuer du **web scraping** de cette url (https://www.scrapethissite.com/pages/simple/) pour r√©cup√©rer les **noms de pays** et le **nombre d'habitants**.\n",
    "\n",
    "- Faire une **requ√™te GET** sur l'url https://www.scrapethissite.com/pages/simple/ gr√¢ce √† la biblioth√®que [requests](https://requests.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0856349",
   "metadata": {},
   "source": [
    "- Analyser la **structure de la page HTML** pour r√©cup√©rer le **nom du pays** et le **nombre d'habitants** gr√¢ce √† la biblioth√®que [Beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). Mettre les donn√©es dans un **dataframe Pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9224446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6b2f8",
   "metadata": {},
   "source": [
    "## üöÄ Pour aller plus loin\n",
    "\n",
    "- Python Web Scraping - Should I use Selenium, Beautiful Soup or Scrapy? [2020] : https://www.youtube.com/watch?v=zucvHSQsKHA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1409ec6",
   "metadata": {},
   "source": [
    "___\n",
    "*üë®‚Äçüè´ [Pierre-Loic BAYART](https://www.linkedin.com/in/pierreloicbayart/) - Formation d√©veloppeur d'applications sp√©cialisation data analyst - Webforce3 - Grenoble Ecole de Management*\n",
    "___\n",
    "Source images d'illustration : Image par I am AFK¬†¬†‚Ä¢¬†¬†So long, and thanks for all the likes! de Pixabay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
